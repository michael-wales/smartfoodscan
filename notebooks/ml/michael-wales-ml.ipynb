{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parquets\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "X_test = pd.read_parquet('../shared_data/X_test.parquet')\n",
    "X_train = pd.read_parquet('../shared_data/X_train.parquet')\n",
    "y_test = pd.read_parquet('../shared_data/y_test.parquet')\n",
    "y_train = pd.read_parquet('../shared_data/y_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluations\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        'MSE': (mse := mean_squared_error(y_test, y_pred)),\n",
    "        'RMSE': mse ** 0.5,\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    for metric, value in metrics.items():\n",
    "        print(f'{metric}: {value:.4f}')\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust scaler\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def robust_scale_dataframe(df, fitted_scaler=None):\n",
    "\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "    if len(numerical_cols) == 0:\n",
    "        raise ValueError('No numerical columns found in the DataFrame.')\n",
    "\n",
    "    if fitted_scaler is None:\n",
    "        scaler = RobustScaler()\n",
    "        df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "    else:\n",
    "        df[numerical_cols] = fitted_scaler.transform(df[numerical_cols])\n",
    "        scaler = fitted_scaler\n",
    "\n",
    "    return df, scaler\n",
    "\n",
    "X_train_scaled, scaler = robust_scale_dataframe(X_train)\n",
    "X_test_scaled, _ = robust_scale_dataframe(X_test, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove text column, flatten ys\n",
    "\n",
    "X_train_textless, X_test_textless = X_train.drop(columns='text'), X_test.drop(columns='text')\n",
    "y_train, y_test = y_train.values.ravel(), y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 164.7835\n",
      "RMSE: 12.8368\n",
      "MAE: 9.2768\n",
      "R2: 0.4209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MSE': 164.78348245159992,\n",
       " 'RMSE': 12.836801877866618,\n",
       " 'MAE': 9.276756727230671,\n",
       " 'R2': 0.4208518809199885}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "def train_linear_regression(X_train, y_train, param_grid=None, search_type='grid', cv=5, n_iter=10):\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    if param_grid:\n",
    "        if search_type == 'grid':\n",
    "            search = GridSearchCV(model, param_grid, cv=cv, scoring='neg_mean_squared_error')\n",
    "        elif search_type == 'random':\n",
    "            search = RandomizedSearchCV(model, param_grid, n_iter=n_iter, cv=cv, scoring='neg_mean_squared_error', random_state=42)\n",
    "        else:\n",
    "            raise ValueError('Invalid search_type. Choose \"grid\" or \"random\".')\n",
    "\n",
    "        search.fit(X_train, y_train)\n",
    "        best_model = search.best_estimator_\n",
    "        print(f'Best Parameters: {search.best_params_}')\n",
    "    else:\n",
    "        best_model = model.fit(X_train, y_train)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "lr_model = train_linear_regression(X_train_scaled.drop(columns='text'), y_train)\n",
    "evaluate_model(lr_model, X_test_scaled.drop(columns='text'), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take too long. One big function for several different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "import time\n",
    "\n",
    "def hyperparameter_tuning(X_train,\n",
    "                          y_train,\n",
    "                          X_test,\n",
    "                          y_test,\n",
    "                          models=None,\n",
    "                          search_type='halving',\n",
    "                          n_iter=20,\n",
    "                          cv=5,\n",
    "                          scoring='r2',\n",
    "                          verbose=1):\n",
    "    '''\n",
    "    Args:\n",
    "        X_train, y_train: Training data\n",
    "        X_test, y_test: Test data\n",
    "        models: Dictionary of models with hyperparameter grids (default = common regressors + XGBoost)\n",
    "        search_type: 'grid', 'random', or 'halving' (default = 'halving' [experimental])\n",
    "        n_iter: Number of iterations (only for RandomizedSearchCV)\n",
    "        cv: Number of cross-validations\n",
    "        scoring: Metric to optimize (default = 'r2')\n",
    "        verbose: Verbosity\n",
    "\n",
    "    Returns:\n",
    "        best_model: The best model found\n",
    "        best_params: Best hyperparameters\n",
    "        all_scores: A dictionary of performance metrics for all models\n",
    "    '''\n",
    "\n",
    "    if models is None:\n",
    "        models = {\n",
    "            'RandomForest': {\n",
    "                'model': RandomForestRegressor(n_jobs=-1),\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 300, 500],\n",
    "                    'max_depth': [None, 10, 30],\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'min_samples_leaf': [1, 2, 4],\n",
    "                    'bootstrap': [True, False]\n",
    "                }\n",
    "            },\n",
    "            'GradientBoosting': {\n",
    "                'model': GradientBoostingRegressor(),\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 300, 500],\n",
    "                    'learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'max_depth': [3, 5, 10]\n",
    "                }\n",
    "            },\n",
    "            'XGBoost': {  # Optimized for speed\n",
    "                'model': XGBRegressor(objective='reg:squarederror', eval_metric='rmse', n_jobs=-1),\n",
    "                'params': {\n",
    "                    'n_estimators': [100, 300, 500],\n",
    "                    'learning_rate': [0.01, 0.1, 0.2],\n",
    "                    'max_depth': [3, 5, 10],\n",
    "                    'subsample': [0.6, 0.8, 1.0],\n",
    "                    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "                }\n",
    "            },\n",
    "            'Ridge': {\n",
    "                'model': Ridge(),\n",
    "                'params': {'alpha': [0.1, 1, 10, 100]}\n",
    "            },\n",
    "            'Lasso': {\n",
    "                'model': Lasso(),\n",
    "                'params': {'alpha': [0.001, 0.01, 0.1, 1, 10]}\n",
    "            },\n",
    "            'SVR': {\n",
    "                'model': SVR(),\n",
    "                'params': {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf', 'poly']}\n",
    "            }\n",
    "        }\n",
    "\n",
    "    all_scores = {}\n",
    "    best_model = None\n",
    "    best_score = float('-inf')\n",
    "    best_params = None\n",
    "\n",
    "    for model_name, config in models.items():\n",
    "        model = config['model']\n",
    "        param_grid = config['params']\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', RobustScaler()),  # Handles outliers\n",
    "            ('model', model)\n",
    "        ])\n",
    "\n",
    "        print(f'Tuning **{model_name}** using **{search_type.upper()} Search**...')\n",
    "\n",
    "        search = None\n",
    "        start_time = time.time()\n",
    "\n",
    "        if search_type == 'grid':\n",
    "            search = GridSearchCV(pipeline, {'model__' + k: v for k, v in param_grid.items()},\n",
    "                                  cv=cv, scoring=scoring, n_jobs=-1, verbose=verbose, refit=False)\n",
    "        elif search_type == 'random':\n",
    "            search = RandomizedSearchCV(pipeline, {'model__' + k: v for k, v in param_grid.items()},\n",
    "                                        n_iter=n_iter, cv=cv, scoring=scoring, n_jobs=-1,\n",
    "                                        random_state=42, verbose=verbose, refit=False)\n",
    "        elif search_type == 'halving':\n",
    "            search = HalvingGridSearchCV(pipeline, {'model__' + k: v for k, v in param_grid.items()},\n",
    "                                         factor=2, cv=cv, scoring=scoring, n_jobs=-1, verbose=verbose, refit=False)\n",
    "        else:\n",
    "            raise ValueError('Invalid search_type. Choose from \"grid\", \"random\", or \"halving\".')\n",
    "\n",
    "        search.fit(X_train, y_train)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f'**{model_name}** tuning completed in {elapsed_time:.2f} seconds.')\n",
    "\n",
    "        # Evaluate and store the performance metrics\n",
    "        y_pred = search.predict(X_test)\n",
    "        model_scores = evaluate_model(y_test, y_pred)\n",
    "\n",
    "        # Store the scores for the current model\n",
    "        all_scores[model_name] = model_scores\n",
    "\n",
    "        # Print the scores for this model\n",
    "        print(f'**{model_name} Performance**:')\n",
    "        for metric, value in model_scores.items():\n",
    "            print(f'{metric}: {value:.4f}')\n",
    "\n",
    "        # Update the best model\n",
    "        if search.best_score_ > best_score:\n",
    "            best_score = search.best_score_\n",
    "            best_model = search.best_estimator_\n",
    "            best_params = search.best_params_\n",
    "\n",
    "        print(f'**Best Params for {model_name}**: {search.best_params_}\\n')\n",
    "\n",
    "    print('\\n**Best Model Selected:**', best_model)\n",
    "    print(f'Best Params: {best_params}')\n",
    "\n",
    "    # Print model performance for all models\n",
    "    for model_name, scores in all_scores.items():\n",
    "        print(f'\\n{model_name}:')\n",
    "        for metric, value in scores.items():\n",
    "            print(f'{metric}: {value:.4f}')\n",
    "\n",
    "    return best_model, best_params, all_scores\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    scores = {\n",
    "        'RMSE': mean_squared_error(y_true, y_pred) ** 0.5,\n",
    "        'MSE': mean_squared_error(y_true, y_pred),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'R2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning **RandomForest** using **HALVING Search**...\n",
      "n_iterations: 8\n",
      "n_required_iterations: 8\n",
      "n_possible_iterations: 8\n",
      "min_resources_: 1277\n",
      "max_resources_: 163516\n",
      "aggressive_elimination: False\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 162\n",
      "n_resources: 1277\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 81\n",
      "n_resources: 2554\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 41\n",
      "n_resources: 5108\n",
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 21\n",
      "n_resources: 10216\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 11\n",
      "n_resources: 20432\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelwales/.pyenv/versions/3.10.6/envs/smartfoodscan/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 5\n",
      "n_candidates: 6\n",
      "n_resources: 40864\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 6\n",
      "n_candidates: 3\n",
      "n_resources: 81728\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "----------\n",
      "iter: 7\n",
      "n_candidates: 2\n",
      "n_resources: 163456\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "**RandomForest** tuning completed in 3028.01 seconds.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "This 'HalvingGridSearchCV' has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/smartfoodscan/lib/python3.10/site-packages/sklearn/utils/_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor._check\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     check_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/smartfoodscan/lib/python3.10/site-packages/sklearn/model_selection/_search.py:371\u001b[0m, in \u001b[0;36m_search_estimator_has.<locals>.check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 371\u001b[0m     \u001b[43m_check_refit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_estimator_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;66;03m# raise an AttributeError if `attr` does not exist\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/smartfoodscan/lib/python3.10/site-packages/sklearn/model_selection/_search.py:351\u001b[0m, in \u001b[0;36m_check_refit\u001b[0;34m(search_cv, attr)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m search_cv\u001b[38;5;241m.\u001b[39mrefit:\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(search_cv)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instance was initialized with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`refit=False`. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is available only after refitting on the best \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters. You can refit an estimator manually using the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`best_params_` attribute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    356\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: This HalvingGridSearchCV instance was initialized with `refit=False`. predict is available only after refitting on the best parameters. You can refit an estimator manually using the `best_params_` attribute",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Try halving for speed\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m best_model, best_params, scores \u001b[38;5;241m=\u001b[39m \u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_textless\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_textless\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhalving\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 119\u001b[0m, in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(X_train, y_train, X_test, y_test, models, search_type, n_iter, cv, scoring, verbose)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m** tuning completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Evaluate and store the performance metrics\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(X_test)\n\u001b[1;32m    120\u001b[0m model_scores \u001b[38;5;241m=\u001b[39m evaluate_model(y_test, y_pred)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Store the scores for the current model\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/smartfoodscan/lib/python3.10/site-packages/sklearn/utils/_available_if.py:43\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__get__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, owner\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mowner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m         out \u001b[38;5;241m=\u001b[39m MethodType(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, obj)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;66;03m# This makes it possible to use the decorated method as an unbound method,\u001b[39;00m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;66;03m# for instance when monkeypatching.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/smartfoodscan/lib/python3.10/site-packages/sklearn/utils/_available_if.py:34\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor._check\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     32\u001b[0m     check_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck(obj)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr_err_msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_result:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr_err_msg)\n",
      "\u001b[0;31mAttributeError\u001b[0m: This 'HalvingGridSearchCV' has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# Try halving for speed\n",
    "\n",
    "best_model, best_params, scores = hyperparameter_tuning(X_train_textless, y_train, X_test_textless, y_test, search_type='halving', n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartfoodscan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
